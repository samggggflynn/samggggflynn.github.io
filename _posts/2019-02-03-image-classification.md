---
layout: post
#标题配置
title: Image Classification（图像分类）（上）
#时间配置
date:   2019-02-03 11:31:00 +0800
#大类配置
categories: CS231n
#小类配置
tag: 笔记
---

* content
{:toc}

# Image Classification（图像分类）
**动机（motivation）：**在本节中，我们将介绍图像分类问题，该问题的任务是从一组固定的类别中为输入图像分配一个标签。这是计算机视觉中的核心问题之一，尽管其简单，但具有各种各样的实际应用。此外，正如我们将在本课程后面看到的那样，许多其他看似不同的计算机视觉任务（例如物体检测，分割）可以简化为图像分类。

**举例（example）：**以下图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”。
-------------------------------------------------------------
![](/styles/images/2019-02-03-image-classification/classify.png)

图像分类的任务，就是对于一个给定的图像，预测它属于的那个分类标签（或者给出属于一系列不同标签的可能性）。图像是3维数组，数组元素是取值范围从0到255的整数。数组的尺寸是宽度x高度x3，其中这个3代表的是红、绿和蓝3个颜色通道。
-------------------------------------------------------------

**挑战（challenges）：**对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难，要记住图像是以3维数组来表示的，数组中的元素是亮度值。

* **视角变化（Viewpoint variation）：**同一个物体，摄像机可以从多个角度来展现。
* **大小变化（Scale variation）：**物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。
* **形变（Deformation）：**很多东西的形状并非一成不变，会有很大变化。
* **遮挡（Occlusion）：**目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的
* **光照条件（Illumination conditions）：**在像素层面上，光照的影响非常大。
* **背景干扰（Background clutter）：**物体可能混入背景之中，使之难以被辨认。
* **类内差异（Intra-class variation）：**一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。

面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。
--------------------------------------------------------------
![](/styles/images/2019-02-03-image-classification/challenges.jpeg)
--------------------------------------------------------------

**数据驱动方法（Data-driven approach）：**如何写一个图像分类的算法呢？这和写个排序算法可是大不一样。怎么写一个从图像中认出猫的算法？搞不清楚。因此，与其在代码中直接写明各类物体到底看起来是什么样的，倒不如说我们采取的方法和教小孩儿看图识物类似：给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是 **数据驱动** 方法。既然该方法的第一步就是收集已经做好分类标注的图片来作为训练集，那么下面就看看数据库到底长什么样：
--------------------------------------------------------------
![](/styles/images/2019-02-03-image-classification/trainset.jpg)

一个有4个视觉分类的训练集。在实际中，我们可能有上千的分类，每个分类都有成千上万的图像。
--------------------------------------------------------------

**图像分类流程（The image classification pipeline.）。**在课程视频中已经学习过，**图像分类**就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：

* **输入（input）：**输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为**训练集**。
* **学习（Learning）：**这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做**训练分类器**或者**学习模型**。
* **评价（Evaluation）：**让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，这样的情况越多越好。

## 最邻近值分类器（Nearest Neighbor Classifier）

作为课程介绍的第一个方法，我们来实现一个**Nearest Neighbor分类器**。虽然这个分类器和卷积神经网络没有任何关系，实际中也极少使用，但通过实现它，可以让读者对于解决图像分类问题的方法有个基本的认识。

**示例图像分类数据集（Example image classification dataset）：CIFAR-10** 一个非常流行的图像分类数据集是[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html)。这个数据集包含了60000张32X32的小图像。每张图像都有10种分类标签中的一种。这60000张图像被分为包含50000张图像的训练集和包含10000张图像的测试集。在下图中你可以看见10个类的10张随机图片。

--------------------------------------------------------------
![](/styles/images/2019-02-03-image-classification/nn.jpg)
**左边：**从[CIFAR-10数据库](http://www.cs.toronto.edu/~kriz/cifar.html)来的样本图像。**右边：**第一列是测试图像，然后第一列的每个测试图像右边是使用Nearest Neighbor算法，根据像素差异，从训练集中选出的10张最类似的图片。
--------------------------------------------------------------

假设现在我们有CIFAR-10的50000张图片（每种分类5000张）作为训练集，我们希望将余下的10000作为测试集并给他们打上标签。Nearest Neighbor算法将会拿着测试图片和训练集中每一张图片去比较，然后将它认为最相似的那个训练集图片的标签赋给这张测试图片。上面右边的图片就展示了这样的结果。请注意上面10个分类中，只有3个是准确的。比如第8行中，马头被分类为一个红色的跑车，原因在于红色跑车的黑色背景非常强烈，所以这匹马就被错误分类为跑车了。

那么具体如何比较两张图片呢？在本例中，就是比较32x32x3的像素块。最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量I\_1和I\_2，然后计算他们的**L1距离：**

d1(I1,I2)=∑p|Ip1−Ip2|d1(I1,I2)=∑p|I1p−I2p|

d\_1 (I\_1, I\_2) = \\sum\_{p} \\left| I^p\_1 - I^p\_2 \\right|

这里的求和是针对所有的像素。下面是整个比较流程的图例：
-----------------------------------------------------------
![](/styles/images/2019-02-03-image-classification/nneg.jpeg)
以图片中的一个颜色通道为例来进行说明。两张图片使用L1距离来进行比较。逐个像素求差值，然后将所有差值加起来得到一个数值。如果两张图片一模一样，那么L1距离为0，但是如果两张图片很是不同，那L1值将会非常大。
-----------------------------------------------------------

下面，让我们看看如何用代码来实现这个分类器。首先，我们将CIFAR-10的数据加载到内存中，并分成4个数组：训练数据和标签，测试数据和标签。在下面的代码中，**Xtr**（大小是50000x32x32x3）存有训练集中所有的图像，**Ytr**是对应的长度为50000的1维数组，存有图像对应的分类标签（从0到9）：